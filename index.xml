<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Shuvo Islam Khan</title>
    <link>https://shuvoislamkhan.github.io/</link>
    <description>Recent content on Shuvo Islam Khan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://shuvoislamkhan.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Reward Hacking in Reinforcement Learning</title>
      <link>https://shuvoislamkhan.github.io/posts/2024-11-28-reward-hacking/</link>
      <pubDate>Thu, 28 Nov 2024 00:00:00 +0000</pubDate>
      
      <guid>https://shuvoislamkhan.github.io/posts/2024-11-28-reward-hacking/</guid>
      <description>&lt;p&gt;Reward hacking occurs when a &lt;a href=&#34;(https://shuvoislamkhan.github.io/posts/2018-02-19-rl-overview/)&#34;&gt;reinforcement learning (RL)&lt;/a&gt; agent &lt;a href=&#34;https://shuvoislamkhan.github.io/posts/2018-01-23-multi-armed-bandit/#exploitation-vs-exploration&#34;&gt;exploits&lt;/a&gt; flaws or ambiguities in the reward function to achieve high rewards, without genuinely learning or completing the intended task. Reward hacking exists because RL environments are often imperfect, and it is fundamentally challenging to accurately specify a reward function.&lt;/p&gt;
&lt;p&gt;With the rise of &lt;a href=&#34;https://shuvoislamkhan.github.io/posts/2019-01-31-lm/&#34;&gt;language models&lt;/a&gt; generalizing to a broad spectrum of tasks and RLHF becomes a de facto method for alignment training, reward hacking in RL training of language models has become a critical practical challenge. Instances where the model learns to modify unit tests to pass coding tasks, or where responses contain biases that mimic a user&amp;rsquo;s preference, are pretty concerning and are likely one of the major blockers for real-world deployment of more autonomous use cases of AI models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Contrastive Representation Learning</title>
      <link>https://shuvoislamkhan.github.io/posts/2021-05-31-contrastive/</link>
      <pubDate>Mon, 31 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://shuvoislamkhan.github.io/posts/2021-05-31-contrastive/</guid>
      <description>&lt;!-- The main idea of contrastive learning is to learn representations such that similar samples stay close to each other, while dissimilar ones are far apart. Contrastive learning can be applied to both supervised and unsupervised data and has been shown to achieve good performance on a variety of vision and language tasks. --&gt;
&lt;p&gt;The goal of contrastive representation learning is to learn such an embedding space in which similar sample pairs stay close to each other while dissimilar ones are far apart. Contrastive learning can be applied to both supervised and unsupervised settings. When working with unsupervised data, contrastive learning is one of the most powerful approaches in &lt;a href=&#34;https://shuvoislamkhan.github.io/posts/2019-11-10-self-supervised/&#34;&gt;self-supervised learning&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    
    <item>
      <title>Evolution Strategies</title>
      <link>https://shuvoislamkhan.github.io/posts/2019-09-05-evolution-strategies/</link>
      <pubDate>Thu, 05 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://shuvoislamkhan.github.io/posts/2019-09-05-evolution-strategies/</guid>
      <description>&lt;!-- Gradient descent is not the only option when learning optimal model parameters. Evolution Strategies (ES)  works out well in the cases where we don&#39;t know the precise analytic form of an objective function or cannot compute the gradients directly. This post dives into several classic ES methods, as well as how ES can be used in deep reinforcement learning. --&gt;
&lt;p&gt;Stochastic gradient descent is a universal choice for optimizing deep learning models. However, it is not the only option. With black-box optimization algorithms, you can evaluate a target function $f(x): \mathbb{R}^n \to \mathbb{R}$, even when you don&amp;rsquo;t know the precise analytic form of $f(x)$ and thus cannot compute gradients or the Hessian matrix. Examples of black-box optimization methods include &lt;a href=&#34;https://en.wikipedia.org/wiki/Simulated_annealing&#34;&gt;Simulated Annealing&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Hill_climbing&#34;&gt;Hill Climbing&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method&#34;&gt;Nelder-Mead method&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Meta Reinforcement Learning</title>
      <link>https://shuvoislamkhan.github.io/posts/2019-06-23-meta-rl/</link>
      <pubDate>Sun, 23 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://shuvoislamkhan.github.io/posts/2019-06-23-meta-rl/</guid>
      <description>&lt;!-- Meta-RL is meta-learning on reinforcement learning tasks. After trained over a distribution of tasks, the agent is able to solve a new task by developing a new RL algorithm with its internal activity dynamics. This post starts with the origin of meta-RL and then dives into three key components of meta-RL. --&gt;
&lt;p&gt;In my earlier post on &lt;a href=&#34;https://shuvoislamkhan.github.io/posts/2018-11-30-meta-learning/&#34;&gt;meta-learning&lt;/a&gt;, the problem is mainly defined in the context of few-shot classification. Here I would like to explore more into cases when we try to &amp;ldquo;meta-learn&amp;rdquo; &lt;a href=&#34;https://shuvoislamkhan.github.io/posts/2018-02-19-rl-overview/&#34;&gt;Reinforcement Learning (RL)&lt;/a&gt; tasks by developing an agent that can solve unseen tasks fast and efficiently.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Domain Randomization for Sim2Real Transfer</title>
      <link>https://shuvoislamkhan.github.io/posts/2019-05-05-domain-randomization/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://shuvoislamkhan.github.io/posts/2019-05-05-domain-randomization/</guid>
      <description>&lt;!-- If a model or policy is mainly trained in a simulator but expected to work on a real robot, it would surely face the sim2real gap. *Domain Randomization* (DR) is a simple but powerful idea of closing this gap by randomizing properties of the training environment. --&gt;
&lt;p&gt;In Robotics, one of the hardest problems is how to make your model transfer to the real world. Due to the sample inefficiency of deep RL algorithms and the cost of data collection on real robots, we often need to train models in a simulator which theoretically provides an infinite amount of data. However, the reality gap between the simulator and the physical world often leads to failure when working with physical robots. The gap is triggered by an inconsistency between physical parameters (i.e. friction, kp, damping, mass, density) and, more fatally, the incorrect physical modeling (i.e. collision between soft surfaces).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Are Deep Neural Networks Dramatically Overfitted?</title>
      <link>https://shuvoislamkhan.github.io/posts/2019-03-14-overfit/</link>
      <pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://shuvoislamkhan.github.io/posts/2019-03-14-overfit/</guid>
      <description>&lt;!-- If you are, like me, confused by why deep neural networks can generalize to out-of-sample data points without drastic overfitting, keep on reading. --&gt;
&lt;p&gt;&lt;span class=&#34;update&#34;&gt;[Updated on 2019-05-27: add the &lt;a href=&#34;#the-lottery-ticket-hypothesis&#34;&gt;section&lt;/a&gt; on Lottery Ticket Hypothesis.]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If you are like me, entering into the field of deep learning with experience in traditional machine learning, you may often ponder over this question: Since a typical deep neural network has so many parameters and training error can easily be perfect, it should surely suffer from substantial overfitting. How could it be ever generalized to out-of-sample data points?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Generalized Language Models</title>
      <link>https://shuvoislamkhan.github.io/posts/2019-01-31-lm/</link>
      <pubDate>Thu, 31 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://shuvoislamkhan.github.io/posts/2019-01-31-lm/</guid>
      <description>&lt;!-- As a follow up of word embedding post, we will discuss the models on learning contextualized word vectors, as well as the new trend in large unsupervised pre-trained language models which have achieved amazing SOTA results on a variety of language tasks. --&gt;
&lt;p&gt;&lt;span class=&#34;update&#34;&gt;[Updated on 2019-02-14: add &lt;a href=&#34;#ulmfit&#34;&gt;ULMFiT&lt;/a&gt; and &lt;a href=&#34;#gpt-2&#34;&gt;GPT-2&lt;/a&gt;.]&lt;/span&gt;&lt;br/&gt;
&lt;span class=&#34;update&#34;&gt;[Updated on 2020-02-29: add &lt;a href=&#34;#albert&#34;&gt;ALBERT&lt;/a&gt;.]&lt;/span&gt;&lt;br/&gt;
&lt;span class=&#34;update&#34;&gt;[Updated on 2020-10-25: add &lt;a href=&#34;#roberta&#34;&gt;RoBERTa&lt;/a&gt;.]&lt;/span&gt;&lt;br/&gt;
&lt;span class=&#34;update&#34;&gt;[Updated on 2020-12-13: add &lt;a href=&#34;#t5&#34;&gt;T5&lt;/a&gt;.]&lt;/span&gt;&lt;br/&gt;
&lt;span class=&#34;update&#34;&gt;[Updated on 2020-12-30: add &lt;a href=&#34;#gpt-3&#34;&gt;GPT-3&lt;/a&gt;.]&lt;/span&gt;&lt;br/&gt;
&lt;span class=&#34;update&#34;&gt;[Updated on 2021-11-13: add &lt;a href=&#34;#xlnet&#34;&gt;XLNet&lt;/a&gt;, &lt;a href=&#34;#bart&#34;&gt;BART&lt;/a&gt; and &lt;a href=&#34;#electra&#34;&gt;ELECTRA&lt;/a&gt;; Also updated the &lt;a href=&#34;#summary&#34;&gt;Summary&lt;/a&gt; section.]&lt;/span&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;img src=&#34;elmo-and-bert.png&#34; style=&#34;width: 60%;&#34; class=&#34;center&#34; /&gt;
&lt;figcaption&gt;Fig. 0. I guess they are Elmo &amp; Bert? (Image source: &lt;a href=&#34;https://www.youtube.com/watch?v=l5einDQ-Ttc&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;)&lt;/figcaption&gt;
&lt;p&gt;We have seen amazing progress in NLP in 2018. Large-scale pre-trained language modes like &lt;a href=&#34;https://blog.openai.com/language-unsupervised/&#34;&gt;OpenAI GPT&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/1810.04805&#34;&gt;BERT&lt;/a&gt; have achieved great performance on a variety of language tasks using generic model architectures. The idea is similar to how ImageNet classification pre-training helps many vision tasks (*). Even better than vision classification pre-training, this simple and powerful approach in NLP does not require labeled data for pre-training, allowing us to experiment with increased training scale, up to our very limit.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Object Detection Part 4: Fast Detection Models</title>
      <link>https://shuvoislamkhan.github.io/posts/2018-12-27-object-recognition-part-4/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://shuvoislamkhan.github.io/posts/2018-12-27-object-recognition-part-4/</guid>
      <description>&lt;!-- Part 4 of the &#34;Object Detection for Dummies&#34; series focuses on one-stage models for fast detection, including SSD, RetinaNet, and models in the YOLO family. These models skip the explicit region proposal stage but apply the detection directly on dense sampled areas. --&gt;
&lt;p&gt;In &lt;a href=&#34;https://shuvoislamkhan.github.io/posts/2017-12-31-object-recognition-part-3/&#34;&gt;Part 3&lt;/a&gt;, we have reviewed models in the R-CNN family. All of them are region-based object detection algorithms. They can achieve high accuracy but could be too slow for certain applications such as autonomous driving. In Part 4, we only focus on fast object detection models, including SSD, RetinaNet, and models in the YOLO family.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Meta-Learning: Learning to Learn Fast</title>
      <link>https://shuvoislamkhan.github.io/posts/2018-11-30-meta-learning/</link>
      <pubDate>Fri, 30 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://shuvoislamkhan.github.io/posts/2018-11-30-meta-learning/</guid>
      <description>&lt;!-- Meta-learning, also known as &#34;learning to learn&#34;, intends to design models that can learn new skills or adapt to new environments rapidly with a few training examples. There are three common approaches: 1) learn an efficient distance metric (metric-based); 2) use (recurrent) network with external or internal memory (model-based); 3) optimize the model parameters explicitly for fast learning (optimization-based). --&gt;
&lt;p&gt;&lt;span class=&#34;update&#34;&gt;[Updated on 2019-10-01: thanks to Tianhao, we have this post translated in &lt;a href=&#34;https://wei-tianhao.github.io/blog/2019/09/17/meta-learning.html&#34;&gt;Chinese&lt;/a&gt;!]&lt;/span&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Flow-based Deep Generative Models</title>
      <link>https://shuvoislamkhan.github.io/posts/2018-10-13-flow-models/</link>
      <pubDate>Sat, 13 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://shuvoislamkhan.github.io/posts/2018-10-13-flow-models/</guid>
      <description>&lt;!-- In this post, we are looking into the third type of generative models: flow-based generative models. Different from GAN and VAE, they explicitly learn the probability density function of the input data. --&gt;
&lt;p&gt;So far, I&amp;rsquo;ve written About two types of generative models, &lt;a href=&#34;https://shuvoislamkhan.github.io/posts/2017-08-20-gan/&#34;&gt;GAN&lt;/a&gt; and &lt;a href=&#34;https://shuvoislamkhan.github.io/posts/2018-08-12-vae/&#34;&gt;VAE&lt;/a&gt;. Neither of them explicitly learns the probability density function of real data, $p(\mathbf{x})$ (where $\mathbf{x} \in \mathcal{D}$) &amp;mdash; because it is really hard! Taking the generative model with latent variables as an example, $p(\mathbf{x}) = \int p(\mathbf{x}\vert\mathbf{z})p(\mathbf{z})d\mathbf{z}$ can hardly be calculated as it is intractable to go through all possible values of the latent code $\mathbf{z}$.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>From Autoencoder to Beta-VAE</title>
      <link>https://shuvoislamkhan.github.io/posts/2018-08-12-vae/</link>
      <pubDate>Sun, 12 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://shuvoislamkhan.github.io/posts/2018-08-12-vae/</guid>
      <description>&lt;!-- Autocoders are a family of neural network models aiming to learn compressed latent variables of high-dimensional data. Starting from the basic autocoder model, this post reviews several variations, including denoising, sparse, and contractive autoencoders, and then Variational Autoencoder (VAE) and its modification beta-VAE. --&gt;
&lt;p&gt;&lt;span class=&#34;update&#34;&gt;[Updated on 2019-07-18: add a section on &lt;a href=&#34;#vq-vae-and-vq-vae-2&#34;&gt;VQ-VAE &amp;amp; VQ-VAE-2&lt;/a&gt;.]&lt;/span&gt;
&lt;br/&gt;
&lt;span class=&#34;update&#34;&gt;[Updated on 2019-07-26: add a section on &lt;a href=&#34;#td-vae&#34;&gt;TD-VAE&lt;/a&gt;.]&lt;/span&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;Autocoder is invented to reconstruct high-dimensional data using a neural network model with a narrow bottleneck layer in the middle (oops, this is probably not true for &lt;a href=&#34;#vae-variational-autoencoder&#34;&gt;Variational Autoencoder&lt;/a&gt;, and we will investigate it in details in later sections). A nice byproduct is dimension reduction: the bottleneck layer captures a compressed latent encoding. Such a low-dimensional representation can be used as en embedding vector in various applications (i.e. search), help data compression, or reveal the underlying data generative factors.&lt;/p&gt;</description>
    </item>
    
   
    
    <item>
      <title>about</title>
      <link>https://shuvoislamkhan.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shuvoislamkhan.github.io/about/</guid>
      <description></description>
    </item>
    
    
  </channel>
</rss>
